
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

\chapter{相关研究}
\label{chap:related}

处理应用服务质量与资源利用率的问题，在互联网公司、芯片厂商还是学术界都在想办法解决
该问题：互联网公司方面，Baidu的Matrix项目、Google的Borg和Omega、Facebook的mesos系统
都尝试在软件架构层面解决该问题；Intel最新发布的Xeon E5-v3系列芯片，ARM芯片等都对QoS
提供了一定的支持；学术界在软硬件调度、划分方向也有大量工作。但这一问题并没有被解决，
本章首先介绍数据中心应用及其服务质量评价指标，并对现有工作进行总结，并分析其局限性。
同时参考网络领域在解决该问题的方案，

实现高效通用数据中心目标的前提在于保障应用服务质量。类似于系统安全需要所有环节安全
才能保障端到端（End-to-End）的安全，服务质量保障也需要应用全生命周期所有环节的支持。
在数据中心层面，这需要从服务器节点内部、服务器之间通信以及分布式架构多个层次协同工作。
近年来，学术界、工业界在这三个层次都不断努力。例如，近年来流行的Software Defined
Networking（SDN）技术\cite{SDN}目标就是解决数据中心网络通信的管理、共享与性能隔离问题。
Google在分布式架构上采用了超时发送备份请求同步后台管理进程等技术[11]来提高服务质量。
单节点内服务质量保障技术已成为短板。由于体系结构上不支持服务质量保障，而主流的软件
隔离技术能对资源容量隔离起到较好的效果，但无法保障性能隔离，无法保障服务质量。
总的来说，国内外在保障应用服务质量方面的研究包括单节点与分布式环境两个方面。
以下分别从这两个方面介绍相关工作。


应用混合的目标分为两方面：一是提高资源利用率，二是保障关键应用的服务质量。现有的运行时
管理方案[15]–[17]大都通过硬件性能计数器对关键应用的性能进行监控，并在性能发生下降时对非
关键应用进行各种处理，以减小由于资源竞争引起的性能问题。

造成资源利用率的核心问题在于计算机资源处于“无管理共享”状态，因此多个应用共享资源时会发
生竞争与干扰，最终导致关键应用性能不可预测。目前尚无很好的技术方案解决计算机资源“无管理
共享”的问题，以Google为代表的工业界采用将在线服务器与离线服务器分离的方法，通过降低在线
服务器的负载来保障在线应用的服务质量。

学术界在共享资源管理方面从2个维度、4个方面开展研究：软件调度、软件划分、硬件调度、硬件
划分。软件调度是通过操作系统/Hypervisor层次进行进程、线程或虚拟机级别的调度，一般调度粒
度较大，需要上下文切换，时间上也需要几毫秒到几十毫秒，不能满足在线应用的快时响应的需求；
软件划分技术能对Cache容量进行划分，但无法管理访存带宽这类资源，且软件划分技术配置调整开
销较大；硬件调度技术能支持访存请求级别的细粒度调度，但灵活性较多，不能根据不同应用按需管
理；硬件划分技术对Cache容量比较有效，但也无法对带宽等进行管理，而且同样面临灵活性差的问
题。面对诸多问题，斯坦福大学Christos Kozyrakis教授提出应该重新考虑整个计算机架构，从应用
特征、硬件隔离、操作系统、机群调度、高效资源管理硬件等多层次协同设计[18]。

\section{调度方法}
\label{sec:other}

实现高效通用数据中心目标的前提在于保障应用服务质量。类似于系统安全需要所有环节安全才能保障端到端（End-to-End）的安全，服务质量保障也需要应用全生命周期所有环节的支持。在数据中心层面，这需要从服务器节点内部、服务器之间通信以及分布式架构多个层次协同工作。近年来，学术界、工业界在这三个层次都不断努力。例如，近年来流行的Software Defined Networking（SDN）技术[15]目标就是解决数据中心网络通信的管理、共享与性能隔离问题。Google在分布式架构上采用了超时发送备份请求同步后台管理进程等技术[11]来提高服务质量。单节点内服务质量保障技术已成为短板。由于体系结构上不支持服务质量保障，而主流的软件隔离技术能对资源容量隔离起到较好的效果，但无法保障性能隔离，无法保障服务质量。

总的来说，国内外在保障应用服务质量方面的研究包括单节点与分布式环境两个方面。以下分别从这两个方面介绍相关工作。

1.2.1 单机保障服务质量研究

单机保障服务质量相关研究包括软件资源隔离技术、软硬件调度技术、硬件支持等。

软件隔离技术：针对数据中心里多个应用相互干扰的问题，一般采取虚拟化的手段在资源共享的条件下保障资源隔离，如虚拟机技术Xen[18]或Linux Container[17]。

传统虚拟机技术通过将多台虚拟机VM部署到物理机上，每台虚拟机运行一个应用或应用的一个组件，每个应用在自己的操作系统环境中独立运行，减少相互之间干扰。但这些隔离主要是资源的隔离，而无法实现性能隔离。例如为不同应用分配不同的访存带宽。而且使用虚拟机也会带来一定的性能损失[20]，增加延迟，带来性能波动。

Linux Container[17]是一种轻量级虚拟化，通过在操作系统层面增添虚拟服务器功能，操作系统内核能够提供多个互相独立的用户态实例。每个用户态实例对于它自己的用户来说都像是一台独立的计算机，有自己独立的网络、文件系统、库函数和系统设置等。操作系统级虚拟化技术的优点是性能开销较小，不需要硬件的特别支持，而且能为用户态实例之间提供一定的隔离性，所以被广泛地应用在虚拟主机服务器环境中。然而，容器虚拟化技术的虚拟对象不是实际的物理资源(处理器、内存和外设)，而是从用户角度出发而抽象的操作系统内部资源资，如CPU时间，内存，I/O带宽等，但如图1.5所示，Container技术对性能隔离效果并不理想。事实上，在性能隔离方面也有相关研究， Rice大学的Druschel等人[21]设计了Resource Container系统, 实现了单台物理机上多个应用间的性能隔离和CPU细粒度资源分配机制支持,然而局部隔离并不能保证全局隔离，Druschel 等人又设计了Cluster Container系统[22],以解决应用在集群范围内的隔离问题。但十几年前，单机核数目非常小，如今单节点已经有几十个核，同时运行的应用也增加了一个数量级，出现了很多新的挑战。

页着色（Page Coloring）[33]是一种以软件方式控制内存物理页映射到处理器缓存上的技术,映射到同一缓存块中的物理页对应同一颜色。基于页着色技术可以实现对共享二级缓存的划分(Partition)[36]，能缓解应用在共享二级缓存上的干扰。Cho等人[34]使用Page Coloring技术来管理共享缓存。Tam等人[35]在Linux内核上实现了基于页面着色的缓存划分策略。而对于DRAM系统，也可以使用页着色技术对共享DRAM颗粒进行划分[37][39]，例如，Liu等人[40]在Linux内核上实现了基于页着色的DRAM颗粒划分。北京大学李晓明教授团队也在这方面做了很多工作[41][42][43]，研究利用页着色技术在虚拟环境下对共享Cache进行了划分。页着色技术能缓解一些粗粒度共享资源层次的干扰，但无法解决微体系结构的干扰，比如共享队列等，并且使用不灵活。总结而言，软件隔离技术能对资源容量隔离起到较好的效果，但无法保障性能隔离，无法保障服务质量。

软硬件调度：在多核微体系结构上，由于共享片上和片外资源的竞争会引起跨核应用之间的干扰。Jason Mars和Neil Vachharajani等人提出了竞争感知的轻量级运行时环境CAER[25]，能在提高利用率的同时减少由竞争引起的跨核干扰问题。他还和Lingjia Tang等人在文章[24]还介绍了CiPE框架，可以直接用于测量和量化多核结构下应用的跨核干扰敏感度。Jason Mars等人还设计了Bubble-Up[23]机制，通过使用气泡（Bubble）来代表内存子系统的可变压力情况，能准确预测在内存子系统中竞争共享资源而导致的性能下降。Lingjia Tang等人在文章[29]提出了一种动静结合的编译方法ReQos，在确保高优先级应用的服务质量的同时让低优先级应用也可以自适应地执行。ReQoS包含一种由配置文件引导的编译技术，来识别低优先级应用中有争议的代码段。这些调度相关的工作，在具有大规模真实应用的Google“混布”数据中心里，使用该机制能在保证延迟敏感性应用的服务质量的同时，能显著提高50%~90%的资源利用率。但这些工作属于Ad-hoc类型，针对特定场景有效，并没有从根本上解决问题。

以CMU的Onur Mutlu为代表的一些学术界专家在提出了一系列调度算法[44][45][46]以缓解内存控制器的不公平问题，从而提高系统吞吐量以及服务质量。但这些算法是固化的，并不能针对某个应用进行调节，不具有灵活性。

体系结构支持：Ravi Iyer在文章[30]中提出了一种保障CMP体系结构上缓存Qos的管理框架，设计了CQos优先级分类、优先级分配和优先级执行。CQos优先级分类和优先级分配采用的是从用户到开发人员驱动的编译检测和基于流的方法；CQos优先级执行则包括（1）选择高速缓存分配、（2）动静态结合设置分区、（3）异构缓存区域。实验结果表明， CQoS在多线程或多核平台上能提高共享缓存的效率和系统性能。然而，文章[30]并没有详细描述保障CMP体系结构上缓存Qos的具体策略和软硬件支持。所以，Ravi Iyer等人又在文章[31]中实现了一种在CMP平台上保障Qos的内存体系结构，允运行时的动态资源再分配，能在减少低优先级应用性能下降的同时优化高优先级应用的性能。Andrew Herdrich等人[32]证明了用于功耗管理的基于速率（rate-based）的技术能适应于CMP结构上缓存/内存的Qos管理，其基本方法是当正在运行的低优先级任务由于资源争用而干扰了高优先级任务的性能时，就减缓核心的处理速率。通过评估时钟调制和频率缩放这两个速率限制机制，发现时钟调制更适用于缓存/内存Qos管理。

Ravi Iyer在体系结构支持服务质量方面做了一些有价值的工作，但主要集中在内存方面，并没有从整个系统角度去考虑。事实上，我们认为这个方向在未来会越来越重要，值得深入研究。
 
1.2.2 分布式环境保障服务质量

在分布式环境下，影响应用服务质量的因素主要是节点故障与干扰引起的长尾延迟，下面将从这两个方面介绍相关优化技术。

软硬件故障：Jean Dean等人设计MapReduce[26]的初衷是使用由成百上千机器组成的集群来处理超大规模的数据，所以，要求必须MapReduce能很好地处理机器故障。MapReduce采用了任务重新调度或重新执行任务（backup task）的方法来解决节点故障或短暂忙碌。比如，如果一个机器的硬盘出了问题，读取数据的速度从30M/s降低到1M/s， MapReduce框架中发送backup task机制来减少这一类长尾延迟。Backup task机制通常只会占用比正常操作多几个百分点的计算资源，但能显著改善因为故障出现的长尾延迟。不过，类似于TCP重传机制，backup task的有效性会随着负载的提高而削弱。


竞争共享资源引起的干扰：为了缓解干扰引起的长尾延迟现象，Dean等人[10]介绍了Google采用的缓解长尾延迟的技术，包括操作系统容器隔离技术[12]、应用优先级管理[13]、备份请求[11]、同步后台管理进程[11]等。R. Kapoor等人在文章[27]中提出了Chronos架构，以降低数据中心应用的长尾延迟。Chronos基于NIC上应用层数据包头字段的请求划分、应用实例负载均衡和NIC负载均衡模块的加载来消除关键通信路径上的共享资源，如内核和网络协议栈，以减少应用延迟以及相关干扰。

这些研究工作从分布式架构上一定程度上缓解了“划分/聚合”模式应用（如搜索、大数据分析等）的长尾延迟，但对“依赖/串行”模式（在线购物、社交等）应用并不显著。另一方面，随着单个服务器节点的核数目不断增加，甚至未来“片上数据中心”[47]出现，单节点内同时运行的应用也会增加，那么干扰将会越来越严重，仅仅依赖分布式架构以及软件方法将无法保障性能隔离，如何从硬件上支持服务质量保障技术将是一个值得关注与研究的方向。


\section{隔离方法}
\label{sec:multifig}

\section{软件定义网络SDN}
\label{sec:background:sdn}

The Need for a New Network Architecture % [REF] "Software-Defined Networking: The New Norm for Networks" (PDF). White paper. Open Networking Foundation. April 13, 2012. Retrieved August 22, 2013.
The explosion of mobile devices and content, server virtualization, and
advent of cloud services are among the trends driving the networking
industry to reexamine traditional network architectures. Many conventional
networks are hierarchical, built with tiers of Ethernet switches arranged in
a tree structure. This design made sense when client-server computing
was dominant, but such a static architecture is ill-suited to the dynamic
computing and storage needs of today’s enterprise data centers,
campuses, and carrier environments. Some of the key computing trends
driving the need for a new network paradigm include:


\section{本章小结}

从现有技术来看，单节点内服务质量保障技术的不足，导致节点内应用相互干扰严重，某种程
度上成为目前数据中心整体服务质量保障的短板，是成为长尾延迟现象的主要因素之一。同时
这也是一个非常具有挑战的问题，这需要跨层次协同设计。美国计算共同委员会（Computing 
Community Consortium）于2012年5月发布的计算机体系结构共同体白皮书《21世纪计算机体系
结构》中也将单节点内保障服务质量作为未来研究方向之一，其中认为[9]：“管理应用之间的相
互作用也带来了挑战。例如，这些应用如何表达服务质量（QoS）目标并且让底层的硬件、操作
系统以及虚拟层共同工作来保障它们。”

