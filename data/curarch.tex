
\iffalse
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

%\chapter{现有体系结构服务质量保障技术评估}
%\label{chap:curarch}

%In todays new processors the number of cores is continuously increasing
%which in turn increase the number of threads or workloads that can 
%simultaneously be run. When multi-threaded
% applications run concurrently, they compete for shared
%resources including L3 cache.  At times, this L3 cache resource contention may 
%result in inefficient space utilization. For example a higher priority thread 
%may end up with lesser L3 cache resource or a cache sensitive app may not get
%optimal cache occupancy thereby degrading the performance.
%Cache Allocation kernel patch helps provides a framework for sharing L3 cache
% so that users can allocate the resource according to set requirements.

随着多线程技术与多核平台的发展，单个节点能够提供的越来越强大的计算资源，为硬件资源共享
提供了足够的支持；而虚拟化技术的发展，特别是新兴的容器技术的出现，更加促进了硬件资源
的共享。目前，主流互联网公司已经将其部分业务迁移到了虚拟化平台或容器平台中，
能过资源共享的方式提高服务器资源利用率，但如何进行有效的任务调度依然是一个待解决的问题。
这其中最关键的两点是：实时精准的性能监控和确定性的性能隔离。
基于这一需求现有的芯片厂商都提出了自己的解决方案， % 可能只有intel的方案
如大部分芯片都支持的Performance Counter功能，可以实时监控IPC、命中率、访存带宽等功能，
Intel在E5-v3系列CPU中更是提出了Resource Director Technology（RDT）技术，
增加的对末级缓存监控（CMT）和访存带宽的监控（MBM），以及末级缓存容量划分功能（CAT）。
本章的将对这些已有技术进行分析，并讨论如何将这些技术应用到数据中心系统中以实现服务质量
保障。
% 验证Loop-back的动态调速资源分配机制的有效性

\section{实验方法介绍}

\subsection{Benchmark与应用}

使用CloudSuite和BigDataBench，代替SPEC

Intel早在多年前便在Sandy Bridge处理器中加入Way-Based的Cache Partitioning技术，
并且由UC Berkeley对该处理器进行了分析对比试验，认为Cache Partitioning能在很多
情况下提升20\%的性能。
该工作主要面向SPEC负载，但数据中心中运行的应用与SPEC存在很大差别[][]，
因此在本章，希望使用现有的服务质量保障技术，对数据中心应用混合，验证其效果。

我们将应用负载分为三类：(1) Guaranteed (2) Burstable (3) Best Effort。
其中第一类是最关键的应用，需要预留足够的资源以保证其性能，对外服务基本属于些类型，
典型包括延迟敏感型的应用（如WebServer、memcache等），XXXX； % 长时在线应用
第二类是次关键的应用，它的负载会随时间出现明显的波动性，因些其资源需求也存在波动，
典型的应用包括：XXXX； % 非关键业务
