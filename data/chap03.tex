
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

\chapter{资源管理可编程体系结构PARD}
\label{chap:pardarch}

本章介绍PARD体系结构的基本架构，
并通过管理员视角介绍PARD体系结构的关键特性，包括：
实现全硬件支持的虚拟化、性能监控与反馈、以及可编程的资源管理机制。
%最后讨论了如何在现有体系结构中扩展以支持PARD的这些关键特性。

\section{PARD体系结构}

PARD是在传统服务器体系结构的基础上进行功能扩展，
实现可管理的硬件资源共享与区分化服务的计算机体系结构实现。
可以从用户、管理员和体系结构三个视角理解PARD体系结构（图\ref{fig:pard-views}）：
从用户的视角，PARD是一个可以划分为多个子机器的计算机，每个子机器可以运行独立的操作系统，
不同用户的子机器之间不会存在干扰，用户可根据自己的需求对资源的使用情况进行约定，
如Cache占用、访存带宽等，对子机器的执行性能可预测；
从管理员的视角，PARD是一台具有硬件资源细粒度管理能力的服务器，
通过服务器上配置的资源管理模块（Platform Resource Manager，PRM），
可以监控每个用户对不同硬件资源的使用情况，并可根据需求对资源使用情况进行调整；
从体系结构的视角，PARD将网络的概念引入到计算机体系结构中，
在体系结构内实现了应用区分，为共享硬件部件增加可编程能力，并实现计算机内统一的资源管理。

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{arch/pard-views.pdf}
  \caption{PARD体系结构}
  \label{fig:pard-views}
\end{figure}

在多应用混合这种共享场景中，隔离性和可管理性是服务器体系结构设计时需要考虑的重要问题。
\textbf{隔离性}是指要让运行在共享环境中的应用无法感知到其它应用的存在，
就像它正在运行在独占的计算机中一样，这其中包含两个层次的概念：
一是资源隔离，即应用独占分配给它的资源；
二是性能隔离，使得应用的性能不会被其它应用所干扰。
现有的软件方案（如多进程、容器、虚拟化）或硬件方案（如LPAR、Logic Domain）
可以很容易实现不同级别的资源隔离，但它们都无法完全实现性能隔离。
首先，在操作系统或虚拟化的软件栈的各个层次中都存在不同程度的共享，
这些共享点在一些特定的场景会产生干扰；
而即使是硬件隔离方案，虽然消除了软件层次的干扰，但在共享硬件资源上的干扰依然存在。
硬件层次的隔离没有发挥应有的效果主要是由于目前的体系结构中并不能识别不同的应用。
\textbf{可管理性}是能够对应用占用的资源进行监控与管理。
由于不同的应用或应用运行的不同阶段，其对资源的需求是不同且不断变化的，
如何获取应用资源需求的变化，以及如何根据这些变化对资源的分配进行调整。

PARD选择了硬件隔离方案，为用户提供逻辑域的抽象以实现资源隔离，
通过使用标签的方式将服务器划分为不同的地址空间，以实现性能隔离；
在各个硬件部件上增加了控制平面与可编程可能，实现共享资源管理；
通过节点内全局的资源管理，实现资源按需分配与动态调整。

\subsection{PARD示例：用户与管理员视角}

本节将从用户和管理员的视角，给出PARD在共享数据中心场景中的应用，
介绍PARD的关键特性，以及如何使用PARD解决硬件资源共享带来的干扰问题，
图\ref{fig:pard-example}为该示例的流程。

1. 在T1和T3时间，用户A和用户B分别希望在服务器上运行应用，
他们将自己的资源需求发送到管理员，管理员在收到请求后，
决定将两个用户的应用运行在同一台PARD服务器上。
在真实的场景中，用户与管理员并不会直接操作服务器，
而是通过如mesos\cite{}、OpenStack\cite{}等集群管理系统使用服务器资源。
这里为了简化描述，将集群管理系统这一层移除，让用户与管理员直接操作服务器。

2. 管理员在T2和T4时刻分别处理用户的请求，并通过服务器的PRM接口将资源需求发送到服务器，
交由运行在PRM中的固件对请求进行处理，并分配资源。
以用户B为例，PRM首先为其创建一个逻辑域（LDom），并根据需要为其分配资源，
该逻辑域的编号为“1”（后续使用LDom1表示该逻辑域）。
由于LDom1是一个普通优先级的应用，PRM为其分配了默认的资源使用策略：
与其它逻辑域共享末级缓存、内存、I/O等硬件资源。
在将这些策略编程到各个设备的控制平面后，PRM完成对LDom1的初始化，并在其中启动操作系统。

3. 在T5时刻，用户C希望执行一个高优先级、延迟敏感型的应用，并通过管理员将请求发送到PRM。
在T6时刻，PRM创建了逻辑域LDom2，并为其分配了高优先级的资源分配策略，
在完成LDom2的初始化后，将用户C的应用部署在该逻辑域中。

4. 在T7和T8时刻，更多的用户将资源需求提交到服务器，服务器的资源利用率持续上升。

5. 在T9时刻，由于服务器内运行的应用在共享末级缓存中产生了严重的干扰，
用户C应用的缓存缺失率急剧上升（>30\%）。
在传统的服务器中，如此高的缓存缺失率会造成应用性能的严重下降，
响应时间出现明显的长尾。而在PARD服务器中，用户C的缓存缺失率上升达到30\%时，
末级缓存会向PRM发送该事件的事件通知，运行在PRM中的固件检测到该事件通知，
执行该事件对应的动作脚本，实现资源的重新分配。
在本例中，该事件的动作脚本将为用户C分配更多的末级缓存容量，以缓解其缺失率更高的问题。
通过以上动作，使得在PARD服务器中用户C应用的性能（响应时间）没有受到严重的影响。

\begin{figure}[t]
  \centering
  \includegraphics{arch/pard-example.pdf}
  \caption{PARD示例}
  \label{fig:pard-example}
\end{figure}

\subsection{PARD关键特性}

在上节中，本文通过实例对PARD体系结构的关键特性做了描述，
本节将对这些特性进行总结（如表\cite{}所示），并简要介绍其实现原理。

% 关键技术点
\textbf{标签化地址空间}\ 传统计算机架构使用单一地址空间，虽然虚拟内存与扩展页表机制
为不同的应用或虚拟机分配独立的逻辑地址空间，但它们还是共享一个物理地址空间。
这种单一地址空间的设计，使得共享的硬件部件不能识别出来自不同应用的请求，造成

传统服务器中共享的硬件资源主要包括处理器、Cache、内存和I/O等，
在当前数据中心多应用混合的场景下，现有体系结构实现（如x86、ARM等）无法区分不同的应用，
使得计算机中的硬件资源正在被无管理的共享使用，应用之间由于共享产生干扰，
严重影响应用的性能。

\textbf{可管理的硬件资源共享}\ 控制平面，提供统一的编程接口；
数据平面，实现功能可编程；
集成标签化地址空间，实现区分化服务；
提供资源监控与配置的功能，实现硬件资源的可管理。

\textbf{资源按需分配}\ 集中式的资源监控，资源全局调节，Trigger=>Action的反馈调节机制。


\section{PARD服务器操作}

本节介绍PARD服务器基本操作流程，包括逻辑域创建、资源调整、以及性能监控与反馈。
首先我们定义一台PARD服务器，本节后续内容将以该PARD服务器为实例，
其主要配置如下：

8个处理器核，每个处理器核中包含私有L1 I-Cache和D-Cache；

共享16MB的L2 Cache，使用24路组相联映射;

共享内存控制器，内存容量为8GB；

共享I/O子系统，包含8个SATA硬盘和4个千兆以太网卡。

该服务器共享硬件资源（处理器核、L2 Cache、内存控制器、I/O子系统）都实现了
上节所述的控制平面，其控制表项目以及实现的功能如表\ref{}所示。
所有控制平面都通过控制平面网络连接到PRM，PRM上运行用于资源管理的固件。

\subsection{逻辑域与虚拟机抽象}

PARD服务器使用逻辑域抽象为用户提供服务，每个逻辑域都是PARD服务器硬件资源的子集，
可直接在其中启动操作系统。不同的逻辑逻辑域独占部分资源，如处理器核、内存、I/O设备；
另一些硬件资源在不同逻辑域中共享，如L2 Cache。
当PRM收到逻辑域的创建请求后，PRM首先确认当前服务器是否有足够的资源满足逻辑域的需求，
如果满足，则为其分配一个本地唯一的逻辑域标识，
之后在各个硬件资源的控制平面中为该逻辑域分配所需的资源。
例如，用户创建的逻辑域需要2个处理器核、2GB内存、一个硬盘和一个网卡,
PRM在确认本地资源充足后，为其分配逻辑域标识LDom\#1，后续的创建流程如下：

（1）查询处理器核的控制平面，找到两个空闲的处理器核，并向其标签寄存器写入LDom\#1，
这两个处理器核后续发出的请求中将都包含该逻辑域标签。

（2）在L2 Cache控制平面中增加LDom\#1的控制表项，由于该用户在创建逻辑域时并没有对
Cache指定特殊需求，因此为其分配默认的替换策略掩码，与其他用户共享L2 Cache。

（3）PRM查询内存地址分配，找到空闲的2GB内存空间，
在内存控制器控制平面中建立逻辑域LDom\#1的控制表项，
将查询到的2GB空闲内存的地址写入控制表项，保存逻辑域与内存地址的关联，
内存控制器在收到后续带有LDom\#1标签的访存请求后，会将查询地址映射信息，
对访存地址进行映射，使得内存控制器对来自不同逻辑域的请求进行区分处理。

（4）PRM为逻辑域分配磁盘和网卡，通过I/O控制平面将两个设备的标签寄存器设置为LDom\#1。
这两个设备对内存的DMA请求中都包含该标签，保证其能够访问到逻辑域的内存地址空间；
当前大部分的PCI-E设备都使用MSI方法产生中断，而MSI的本质是对特殊地址的访存请求，
该请求中已经包含了逻辑域标签，因此中断请求能够被正确的发送到分配给该逻辑域的处理器核。

（5）PRM查询这两个设备的物理地址（PA）和所需的I/O地址空间长度，
在逻辑域的地址空间中为这两个设备分配地址（LA），
通过I/O控制平面将分配的PA与LA记录到LDom\#1的控制表项。

在资源分配完成后，PRM通过处理器控制平面，将两个处理器核复位，
之后并选择一个处理器核做为BP，令其开始执行BIOS代码，并启动操作系统。
由于不同的逻辑域使用不同的标识，在整个计算机的数据通路中都能够根据该标识对逻辑域实现区分，
实现逻辑域之间的资源隔离。

在创建逻辑域时，同时还可以指定其性能参数，如Cache替换策略掩码、访存调度优先级、
I/O带宽等，各个硬件部分根据其控制平面中指定的性能参数实现对不同逻辑域的区分化服务。


\subsection{资源调整}

用户的应用在运行时对硬件资源的需求会发生变化，PARD提供了运行时调整硬件资源分配的方法，
允许用户根据需求在运行时对逻辑域的资源分配进行调整，以满足应用的需求。
硬件资源包括可透明调整的资源，如Cache容量、访存带宽等；
也包括需要操作系统支持的资源，如处理器核、内存容量、I/O设备。




\subsection{性能监控与反馈}

性能监控与反馈主要得益于控制平面的设计，通过在硬件上增加控制平面，对请求进行处理，
可以获得不同的应用的状态。如Cache缺失率、访存延迟等。
并通过一个可编程的触发逻辑，当特定事件发生后，将消息通过统一的控制平面网络，
发送到集中式的资源管理模块PRM，由PRM对资源分配进行调整。

在第\ref{chap:}中将对控制平面的设计，以及资源监控进行详细的分析。


\section{小结}

